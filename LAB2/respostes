# LAB 2
Joaquim Ferrer Sagarra, PCA QP-2020-21

## Accounting Tools
2. 
	- /home (NFS)
	```
	> /usr/bin/time ./popul > ./hola.txt   
	2.21user 0.01system 0:02.76elapsed 80%CPU (0avgtext+0avgdata 1236maxresident)k
	0inputs+97664outputs (0major+63minor)pagefaults 0swaps
	```
	- /dades (CIFS)
	```
	> /usr/bin/time ./popul > /dades/joaquim.ferrer/linux/test.txt
	2.50user 0.12system 2:16.43elapsed 1%CPU (0avgtext+0avgdata 1324maxresident)k
	0inputs+0outputs (0major+66minor)pagefaults 0swaps
	```
	- /tmp (Disk)
	- Explicació: /dades i /home usen un percentatge menor de CPU perquè estan muntats en xarxa. Aixó augmenta substancialment el temps de wait del procés. També podem extreure d'aquestes mesures que NFS resulta ser molt més eficients que un disc muntat a través d'SMB (cifs).

3. 
	- /home (NFS)
	```
	usr/bin/time ./pi > ./hola
7.13user 0.01system 0:07.14elapsed 99%CPU (0avgtext+0avgdata 1368maxresident)k
0inputs+72outputs (0major+73minor)pagefaults 0swaps
	```
	- /dades (CIFS)
	```
	> /usr/bin/time ./pi > /dades/joaquim.ferrer/linux/test.txt
	Command terminated by signal 2
	7.64user 0.25system 4:45.31elapsed 2%CPU (0avgtext+0avgdata 1332maxresident)k
	0inputs+0outputs (0major+73minor)pagefaults 0swaps

	```
	- /tmp (disc)
	```
	> /usr/bin/time ./pi > /tmp/test.txt
	7.11user 0.00system 0:07.12elapsed 99%CPU (0avgtext+0avgdata 1400maxresident)k
	0inputs+0outputs (0major+75minor)pagefaults 0swaps
	```
	- Sí que hi ha una diferència clara entre els temps d'execució ente NFS, CIFS i Disc. A partir d'ara consideraré els temps de redirecció a /tmp, és a dir, a disc.

 	-  El percentatge de CPU (%CPU) és el percentatge del total de temps d'execució en el que el programa ha estat ocupant CPU, és a dir fent calculs útils pel programa. El temps de wait (espera en operacions de I/O) és temps en el que el procés esta bloquejat esperant el resultat d'una operació i per tant no es compta dons del temps de CPU. Com podem veure en els resultats de temps anteriors, quan es redirigeix a NFS i a CIFS augmenta considerablement el temps de wait i es pot veure per mitjà de la disminució del %CPU.
	- Una alte eina que podem usar és _perf stat_ que ens permet amb el flag _-r_ tenir una repetició de programa. També podem accedit a contadors harware amb els flags -d -d -d (tres cops -d per accedir a informació detallada dels contadors). Per accedir als contadors hardware també podem usar les eines d'Operf com _ocount_ que ens permet crear Samples cert nombre d'events hardware donats. A continuació l'executaré per mostrar els cicles d'execució.
		- perf:
		``` 	
		> perf stat -r 3 -d -d -d ./PCA/LAB2/lab2_session/pi > /tmp/hola.txt

 Performance counter stats for './PCA/LAB2/lab2_session/pi' (3 runs):

           7153.02 msec task-clock                #    1.000 CPUs utilized            ( +-  0.12% )
                12      context-switches          #    0.002 K/sec                    ( +- 12.73% )
                 0      cpu-migrations            #    0.000 K/sec                  
                60      page-faults               #    0.008 K/sec                    ( +-  0.96% )
       24234664514      cycles                    #    3.388 GHz                      ( +-  0.11% )  (30.67%)
       21171827141      instructions              #    0.87  insn per cycle           ( +-  0.03% )  (38.39%)
         916405735      branches                  #  128.115 M/sec                    ( +-  0.22% )  (38.43%)
         109868197      branch-misses             #   11.99% of all branches          ( +-  0.13% )  (38.49%)
        9109791015      L1-dcache-loads           # 1273.559 M/sec                    ( +-  0.03% )  (38.53%)
           4624415      L1-dcache-load-misses     #    0.05% of all L1-dcache hits    ( +-  9.90% )  (38.55%)
            288655      LLC-loads                 #    0.040 M/sec                    ( +- 37.62% )  (30.81%)
             12536      LLC-load-misses           #    4.34% of all LL-cache hits     ( +- 48.55% )  (30.79%)
   <not supported>      L1-icache-loads                                             
           4660341      L1-icache-load-misses                                         ( +- 20.78% )  (30.79%)
        9109267637      dTLB-loads                # 1273.486 M/sec                    ( +-  0.05% )  (30.78%)
             43941      dTLB-load-misses          #    0.00% of all dTLB cache hits   ( +- 34.21% )  (30.75%)
             31630      iTLB-loads                #    0.004 M/sec                    ( +- 40.99% )  (30.72%)
             16253      iTLB-load-misses          #   51.39% of all iTLB cache hits   ( +- 46.94% )  (30.68%)
   <not supported>      L1-dcache-prefetches                                        
   <not supported>      L1-dcache-prefetch-misses                                   

           7.15394 +- 0.00841 seconds time elapsed  ( +-  0.12% )
		```
		- ocount:
 		```
		> ocount --event=cpu_clk_unhalted n> ./pi.g.pg
Events were actively counted for 7.1 seconds.
Event counts (actual) for /home2/users/alumnes/1227379/PCA/LAB2/lab2_session/pi.g.pg:
        Event                           Count                    % time counted
        cpu_clk_unhalted                24,021,115,047           100.00
		```
4. 
	- Speed-up O0 vs O3:
		```
		O0 time: 7.11user 0.01system 0:07.13elapsed 99%CPU (0avgtext+0avgdata 1440maxresident)k
		03 time: 3.06user 0.00system 0:03.07elapsed 99%CPU (0avgtext+0avgdata 1292maxresident)k

		speed-up user + system = 7.12/3.06 = 2.327
		``` 
## Profiling Tools
###  Profiling with _gprof_ and _Valgrind_
5. 
		(a) Buscar la rutina més invocada --> DIVIDE
		```
		amb valgrind:
			> valgrind --tool=callgrind ./pi.O0.g.static
		amb gprof
			> gprof -b ./pi.O0.pg.g.static
		```
		(b) La rutina que consumeix més temps es pot veure amb les mateixes comandes, és DIVIDE
		(c) La línea que més consumeix --> pi.c:18 que consumeix el 37% del temps de CPU
		```
		amb valgrind: 
			--> A la part de source code de cada rutina
		amb el callgrind: 
			> callgrind_annotate --auto=yes callgrind.out.12010
		amb el gprof:
			> gprof -b -l ./pi.O0.pg.g.static
		```
		(d) No apareix el codi de sistema. Perque pugués apareixer caldria compilar el sistema amb pg o instrumentar-lo amb valgrind. Cosa que no tenim permissos per fer

- A partir d'aqui estaré usant la meva maquina personal Linux 5.10.16-arch1-1:
    ```
    Architecture:                    x86_64
    CPU op-mode(s):                  32-bit, 64-bit
    Byte Order:                      Little Endian
    Address sizes:                   39 bits physical, 48 bits virtual
    CPU(s):                          4
    On-line CPU(s) list:             0-3
    Thread(s) per core:              2
    Core(s) per socket:              2
    Socket(s):                       1
    NUMA node(s):                    1
    Vendor ID:                       GenuineIntel
    CPU family:                      6
    Model:                           78
    Model name:                      Intel(R) Core(TM) i5-6200U CPU @ 2.30GHz
    Stepping:                        3
    CPU MHz:                         762.802
    CPU max MHz:                     2800,0000
    CPU min MHz:                     400,0000
    BogoMIPS:                        4801.00
    Virtualization:                  VT-x
    L1d cache:                       64 KiB
    L1i cache:                       64 KiB
    L2 cache:                        512 KiB
    L3 cache:                        3 MiB
    NUMA node0 CPU(s):               0-3

    ```
6.
            (a i b) Es pot veure com s'eliminen algunes rutines i els pesos es reparteixen. Això és per que s'ha fet inlining i s'ha modificat les operacions de llarga latència per altres de latencia menor.

### Profiling with _oprofile_
7. min count --> 2000003. Com més aslt és el count més baix és el numero de samples perquè els samples conten els coprs que s'ha cridat la rutina cada _count_ vegades.
    ```
    > sudo operf --event=cpu_clk_unhalted:2000003 ./pi.O0.g
    > opreport -l
    samples  %        image name               symbol name
    6485     51.4438  pi.O0.g                  DIVIDE
    3123     24.7739  pi.O0.g                  SUBTRACT
    2748     21.7991  pi.O0.g                  LONGDIV
    10        0.0793  libc-2.33.so             putchar
    8         0.0635  kallsyms                 __fget_light
    8         0.0635  kallsyms                 n_tty_write
    8         0.0635  kallsyms                 vfs_write
    7         0.0555  kallsyms                 _raw_spin_lock_irqsave
    6         0.0476  kallsyms                 new_sync_write
    5         0.0397  kallsyms                 __queue_work
    ...
    ```
8. Procedim amb les mateixes comandes amb un binari compilat amb O3. Podem observar que O3 ha eliminat les funcions DIVIDE SUBSTRACT i LONGFIV que queden concentrades dins de la rutina calculate. A més, mirant el codi amb _opannotate_ es pot apreciar que es redueix substancialment el nombre de samples que marquen les operacions més pesades (les multiplicacions i les divisions). Al mirar l'assambler sembla que hagi canviar la divisió per un shift de bits i una multiplicació.

###  Profiling with _perf_
    Els resultats son els mateixos que podiem veure anteriorment però perf ens permet posar-ho en una interficie per terminal bastant bona i ben usable. A més, ens permet per a cada linea del codi en C veure quina traducció s'ha fet en assambler.
    ```
    > perf record -e cycles -c 2000003 ./pi.O0.g> /dev/null
    > perf report/annotate
    ```

### Profiling using pin
10. 
    |                    | gcc O0      | gcc O3     |
    |--------------------|-------------|------------|
    | Total Instructions | 21238785662 | 7639695431 |
    | Stack Reads        | 7489341397  | 1605161    |
    | Stack Writes       | 1803843293  | 1642638    |
    | IDIV + DIV         | 400380202   | 100090132  |
    | IMUL + MUL         | 400444898   | 530786212  |
    
    comando:
    ```
    >  ../../../pin -t obj-intel64/insmix.so -- ../../../../PCA-FIB/LAB2/lab2_session/pi.O0.g 10000
    ``` 
### Instrumenting with system calls and PAPI
12. 
    (a) La crida a sistema time conta segons des de l'epoch usant el rellotge de la computadora de manera que no pot tenir en compte els canvis de contexts i no podrà contar el CPU time. Només tindrà l'epalsed.
    (b) Amb el clock_gettime si que podrem calcular el temps de CPU usant el rellotge CLOCK_PROCESS_CPUTIME_ID. Aquesta crida té més presició perquè permet calcular a nivell de nanosegons. D'aquesta manera podrem calcular aquests temps amb les seguents crides a sistema:
        ```
        > clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &CPU_time); # CPU time
        > clock_gettime(CLOCK_REALTIME, &elapsed_time); # elapsed time.

        ## CPU_time i elapsed_time son structs del típus timespec de time.h.
        ```
    (c)  

### Tracing Tools
#### strace
13.
```
> strace -c ./pi > /dev/null

% time     seconds  usecs/call     calls    errors syscall
------ ----------- ----------- --------- --------- ----------------
 89,22    0,020611           0     22006           write
  3,82    0,000883         883         1           execve
  1,60    0,000370          46         8           mmap
  1,43    0,000330          27        12        10 openat
  1,15    0,000266          22        12         9 newfstatat
  0,64    0,000148          74         2         1 arch_prctl
  0,57    0,000131         131         1           brk
  0,48    0,000110          36         3           mprotect
  0,34    0,000079          19         4           pread64
  0,32    0,000073          73         1           munmap
  0,18    0,000041          41         1         1 access
  0,16    0,000037          18         2           close
  0,10    0,000023          23         1           read
------ ----------- ----------- --------- --------- ----------------
```

14. 
```strace -e trace=write ./pi > /dev/null``` ens mostra totes les crides a write, els seus paràmetres i el codi de retorn.

#### ltrace

15.

```
> ltrace -c ./pi > /dev/null
% time     seconds  usecs/call     calls      function
------ ----------- ----------- --------- --------------------
 39.93    0.809859          80     10005 putchar
 29.29    0.593997          59     10040 fprintf
 25.07    0.508571          50     10007 memset
  5.22    0.105788          58      1800 fputc
  0.48    0.009814          60       161 fwrite
  0.01    0.000228         228         1 setbuf
------ ----------- ----------- --------- --------------------
100.00    2.028257                 32014 total
```













